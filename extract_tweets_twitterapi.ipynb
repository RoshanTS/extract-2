{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extract_tweets_twitterapi.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fNHDli2dPGOn",
        "RlwWe7qR-zFr",
        "UXdtQ3eQG4gQ",
        "nR7TQkmLJIIk",
        "lmlrojktKQXy"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoshanTS/pfe-estia/blob/extract_twitter_script/extract_tweets_twitterapi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FReQ3DBqtmR",
        "colab_type": "text"
      },
      "source": [
        "# Script d'extraction de données twitter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjEdooQfqt1f",
        "colab_type": "text"
      },
      "source": [
        "##Importations of Python modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD4B1uAQuqXt",
        "colab_type": "text"
      },
      "source": [
        "We import the following libraries :\n",
        "\n",
        "*   [tweepy](https://docs.tweepy.org/en/latest/) :  python client for the official [Twitter API](https://developer.twitter.com/en.html) \n",
        "*   [textblob](https://docs.tweepy.org/en/latest/) : python library for processing textual data\n",
        "*  [os](https://docs.python.org/fr/2.7/library/os.html)\n",
        " : contient diverses fonctions pour gérer l'os\n",
        "\n",
        "* [pandas](https://pandas.pydata.org/pandas-docs/version/0.25/) : python library for data analysis\n",
        "\n",
        "* [re](https://docs.python.org/3/library/re.html) : python library for regular expressions\n",
        "\n",
        "* [nltk](https://www.nltk.org/) : python library to do things like   tokenization, stemming, .."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gpWc4d-tjwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy \n",
        "import textblob\n",
        "import os\n",
        "import pandas\n",
        "import re\n",
        "import nltk\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5M6MSXXzndO",
        "colab_type": "text"
      },
      "source": [
        "We're going to use [OAuthHandler](http://docs.tweepy.org/en/v3.5.0/auth_tutorial.html) to deal with authentification :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usQ4wRGvxFS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tweepy import OAuthHandler \n",
        "from textblob import TextBlob "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNHDli2dPGOn",
        "colab_type": "text"
      },
      "source": [
        "## Quick sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XVoyEq5qt9N",
        "colab_type": "text"
      },
      "source": [
        "*We* define a classe Twitter client :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjUyj5Hv3sN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TwitterClient(object): \n",
        "\t''' \n",
        "\tGeneric Twitter Class for sentiment analysis. \n",
        "\t'''\n",
        "\tdef __init__(self): \n",
        "\t\t''' \n",
        "\t\tClass constructor or initialization method. \n",
        "\t\t'''\n",
        "\t\t# keys and tokens from the Twitter Dev Console \n",
        "\t\tconsumer_key = 'MlbpfXnAwJeQzQlRYK0dKJ6nB'\n",
        "\t\tconsumer_secret = 'cTZLfoM7xOHpFjSfzUW0Ff0AsKPNsqEOhjMNiMbNW6Eg0NZpWr'\n",
        "\t\taccess_token = '1179886074614689793-VLHbcHpSJoXkml9wVMqd9gIcSs4zMS'\n",
        "\t\taccess_token_secret = 'Vnpf7cZp2uIUsdDDV6egSHdxDQXyCHf7INdKVa8Uqs2H4'\n",
        "\n",
        "\t\t# attempt authentication \n",
        "\t\ttry: \n",
        "\t\t\t# create OAuthHandler object \n",
        "\t\t\tself.auth = OAuthHandler(consumer_key, consumer_secret) \n",
        "\t\t\t# set access token and secret \n",
        "\t\t\tself.auth.set_access_token(access_token, access_token_secret) \n",
        "\t\t\t# create tweepy API object to fetch tweets \n",
        "\t\t\tself.api = tweepy.API(self.auth) \n",
        "\t\texcept: \n",
        "\t\t\tprint(\"Error: Authentication Failed\") \n",
        "\n",
        "\tdef clean_tweet(self, tweet): \n",
        "\t\t''' \n",
        "\t\tUtility function to clean tweet text by removing links, special characters \n",
        "\t\tusing simple regex statements. \n",
        "\t\t'''\n",
        "\t\treturn ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
        "\n",
        "\tdef get_tweet_sentiment(self, tweet): \n",
        "\t\t''' \n",
        "\t\tUtility function to classify sentiment of passed tweet \n",
        "\t\tusing textblob's sentiment method \n",
        "\t\t'''\n",
        "\t\t# create TextBlob object of passed tweet text \n",
        "\t\tanalysis = TextBlob(self.clean_tweet(tweet)) \n",
        "\t\t# set sentiment \n",
        "\t\tif analysis.sentiment.polarity > 0: \n",
        "\t\t\treturn 'positive'\n",
        "\t\telif analysis.sentiment.polarity == 0: \n",
        "\t\t\treturn 'neutral'\n",
        "\t\telse: \n",
        "\t\t\treturn 'negative'\n",
        "\n",
        "\tdef get_tweets(self, query, count = 10): \n",
        "\t\t''' \n",
        "\t\tMain function to fetch tweets and parse them. \n",
        "\t\t'''\n",
        "\t\t# empty list to store parsed tweets \n",
        "\t\ttweets = [] \n",
        "\n",
        "\t\ttry: \n",
        "\t\t\t# call twitter api to fetch tweets \n",
        "\t\t\tfetched_tweets = self.api.search(q = query, count = count) \n",
        "\n",
        "\t\t\t# parsing tweets one by one \n",
        "\t\t\tfor tweet in fetched_tweets: \n",
        "\t\t\t\t# empty dictionary to store required params of a tweet \n",
        "\t\t\t\tparsed_tweet = {} \n",
        "\n",
        "\t\t\t\t# saving text of tweet \n",
        "\t\t\t\tparsed_tweet['text'] = tweet.text \n",
        "\t\t\t\t# saving sentiment of tweet \n",
        "\t\t\t\tparsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
        "\n",
        "\t\t\t\t# appending parsed tweet to tweets list \n",
        "\t\t\t\tif tweet.retweet_count > 0: \n",
        "\t\t\t\t\t# if tweet has retweets, ensure that it is appended only once \n",
        "\t\t\t\t\tif parsed_tweet not in tweets: \n",
        "\t\t\t\t\t\ttweets.append(parsed_tweet) \n",
        "\t\t\t\telse: \n",
        "\t\t\t\t\ttweets.append(parsed_tweet) \n",
        "\n",
        "\t\t\t# return parsed tweets \n",
        "\t\t\treturn tweets \n",
        "\n",
        "\t\texcept tweepy.TweepError as e: \n",
        "\t\t\t# print error (if any) \n",
        "\t\t\tprint(\"Error : \" + str(e)) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HmOykkc8-1T",
        "colab_type": "text"
      },
      "source": [
        "We define a function main :\n",
        "\n",
        "\n",
        "1.   query sur l'api twitter\n",
        "2.   print positive versus negative sentiment analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5nJYyn47Ig0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def main(query): \n",
        "\t# creating object of TwitterClient Class \n",
        "\tapi = TwitterClient() \n",
        "\t# calling function to get tweets \n",
        "\ttweets = api.get_tweets(query, count = 200) \n",
        "\n",
        "\t# picking positive tweets from tweets \n",
        "\tptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
        "\t# percentage of positive tweets \n",
        "\tprint(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
        "\t# picking negative tweets from tweets \n",
        "\tntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
        "\t# percentage of negative tweets \n",
        "\tprint(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets))) \n",
        "\t# percentage of neutral tweets \n",
        "#\tprint(\"Neutral tweets percentage: {} %\".format(100*len(tweets - ntweets - ptweets)/len(tweets))) \n",
        "\n",
        "\t# printing first 5 positive tweets \n",
        "\tprint(\"\\n\\nPositive tweets:\") \n",
        "\tfor tweet in ptweets[:10]: \n",
        "\t\tprint(tweet['text']) \n",
        "\n",
        "\t# printing first 5 negative tweets \n",
        "\tprint(\"\\n\\nNegative tweets:\") \n",
        "\tfor tweet in ntweets[:10]: \n",
        "\t\tprint(tweet['text']) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH1vKVyg7XmK",
        "colab_type": "text"
      },
      "source": [
        "We apply our analysis to the tweets featuring \"Hong Kong\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-XRd9Hj4Al9",
        "colab_type": "code",
        "outputId": "3a9df7fd-3e78-475f-b36e-ee3715d6c50b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        }
      },
      "source": [
        "\n",
        "if __name__ == \"__main__\": \n",
        "\t# calling main function \n",
        "\tmain('#HongKong') \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive tweets percentage: 23.728813559322035 %\n",
            "Negative tweets percentage: 18.64406779661017 %\n",
            "\n",
            "\n",
            "Positive tweets:\n",
            "RT @joshuawongcf: Last week, the #HongKong Government invoked the Emergency Regulations Ordinance to outlaw face masks, curbing our right t…\n",
            "RT @Jay_Watt: Harry Harrison #cartoon in today's @SCMPNews pointing out the new normal for the #HongKong police: they absolutely will deman…\n",
            "RT @realKyleOlbert: I met a kind old man from #Guangdong Province today &amp; asked him for his opinion on #HongKong.\n",
            "\n",
            "I was startled to hear h…\n",
            "RT @9GAG: Blizzard: Not us\n",
            "#HongKong \n",
            "-\n",
            "Original comic: @JakeClarkDude https://t.co/Kp9ACaz4c1\n",
            "RT @BoycottHegemony: This is the #CCP world we live in now. WAKE UP!\n",
            "\n",
            "A Sydney #gamingstartup has been hit by a concerted #cyberattack afte…\n",
            "RT @SenRickScott: As the first Senator to visit #HongKong since the protests started, my message is simple. To the brave people of HK: We a…\n",
            "RT @patrickyflee: Female student of the Chinese University of Hong Kong removes mask and narrates her experience of sexual assault by the H…\n",
            "RT @AnnieBoyajian: Honored to stand with friends tonight defending free speech in #America, standing in solidarity with #HongKong, and spea…\n",
            "RT @chillilucas_hk: Guys! You are awesome! ♥️\n",
            "We already passed 4k Subs in the new channel!\n",
            "How can I thank you enough? I promise I will co…\n",
            "I would really, really like if someone could find this for me. It was a news interview but I don't remember what st… https://t.co/a4bZv2GaqP\n",
            "\n",
            "\n",
            "Negative tweets:\n",
            "RT @hayashikakeru: [1/3] Full Eng subtitled video of #CUHK student's tearful testimony abt horrific abuses by #Hongkong police against arre…\n",
            "RT @hayashikakeru: [3/3] Full Eng subtitled video of #CUHK student's tearful testimony abt horrific abuses by #Hongkong police against arre…\n",
            "RT @goldenp11462989: 请战友们广传\n",
            "🙏🙏\n",
            "受到性侵女孩子勇敢的证词！\n",
            "Full Eng subtitled video of #CUHK student's tearful testimony abt horrific abuses by #Hongkong…\n",
            "RT @RaptorBuzz: A #HongKong girl studying at CUHK recalled the nightmarish experience of her and other arrestees at #SanUkLing. She asked t…\n",
            "RT @hayashikakeru: [2/3] Full Eng subtitled video of #CUHK student's tearful testimony abt horrific abuses by #Hongkong police against arre…\n",
            "RT @AnneChaAsia: RT @thetimeusedtobe testimony from #SanUkLing detention and torture center. There's massive #HKPolice abuse in the streets…\n",
            "RT @Woppa1Woppa: Holy shit!!!  This is the protester girl we were tweeting about a few weeks ago who went missing!!! 😡😡😡\n",
            "\n",
            "She's dead!\n",
            "\n",
            "#Hon…\n",
            "Disgusting @Apple pleases #CCP #China by sacrificing #Hongkong public safetly. #Apple #Kowtow https://t.co/cVOSdopLVp\n",
            "RT @lukedepulford: #HongKong your pressure is working! See this letter from @DominicRaab \n",
            "👉Apologising for previous reply.\n",
            "👉 🚨🚨Leaving door…\n",
            "RT @VoCommunism: Come out and show your support for #HongKong as the @WashWizards match up with the Guangzhou Long-Lions.\n",
            "\n",
            "Doors open at 6p…\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjelTUpB-qUv",
        "colab_type": "text"
      },
      "source": [
        "## Extract twitter data from a query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoqbAyxtAmVz",
        "colab_type": "text"
      },
      "source": [
        "### Authentifaction parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItWG6NyaAmyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_key_token = {'consumer_key' : 'MlbpfXnAwJeQzQlRYK0dKJ6nB',\n",
        "                  'consumer_secret' : 'cTZLfoM7xOHpFjSfzUW0Ff0AsKPNsqEOhjMNiMbNW6Eg0NZpWr',\n",
        "                  'access_token' : '1179886074614689793-VLHbcHpSJoXkml9wVMqd9gIcSs4zMS',\n",
        "                  'access_token_secret' : 'Vnpf7cZp2uIUsdDDV6egSHdxDQXyCHf7INdKVa8Uqs2H4'\n",
        "                 }\n",
        "\n",
        "\n",
        "auth = tweepy.OAuthHandler(dict_key_token['consumer_key'], dict_key_token['consumer_secret'])\n",
        "auth.set_access_token(dict_key_token['access_token'], dict_key_token['access_token_secret'])\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlwWe7qR-zFr",
        "colab_type": "text"
      },
      "source": [
        "### Part 1 : how to search for tweets ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylEozL9b_XtV",
        "colab_type": "text"
      },
      "source": [
        "We define variables linked to our search :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLqmQ70i7S3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#content of our query\n",
        "search_words = \"Hong Kong\"\n",
        "\n",
        "#we want tweets starting from ..\n",
        "date_since = \"2019-10-01\"\n",
        "\n",
        "#we want a given number of tweets\n",
        "nb_tweets = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0El7SOop_fqb",
        "colab_type": "text"
      },
      "source": [
        "Then , we collect tweets (note that we could specify the language) and print them :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8Onlqko_ANK",
        "colab_type": "code",
        "outputId": "f2535442-608c-4830-e5b7-72db70dcc07b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "#Collect tweets\n",
        "tweets = tweepy.Cursor(api.search,\n",
        "                      q=search_words,\n",
        "                      lang=\"en\",  \n",
        "                       since=date_since).items(nb_tweets)\n",
        "\n",
        "# Iterate and print tweets\n",
        "\n",
        "for tweet in tweets:\n",
        "    print(tweet.text)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To be honest,\n",
            "the whole #BoycottBlizzard seems like hindsight.\n",
            "I mean, what's the real reason that meddling with th… https://t.co/m8wszLAH4q\n",
            "Good 3 Qs: “When was @hkmaplive “used maliciously to target individual officers for violence”?\n",
            "When was it used to… https://t.co/VtRybpwAbv\n",
            "RT @JesseKellyDC: REMINDER: There is no “impeachment probe”. The House hasn’t voted on it cause they don’t have the votes and their story i…\n",
            "I think its so cool my great grandfather is from Hong Kong 🇭🇰\n",
            "RT @Nicole__1022: A follow up: CCP netizens reaction to Adam Silvers statement on NBA\n",
            "\n",
            "If I m not mistaken, thats a blatant statement calli…\n",
            "RT @blakersdozen: Scoop: Blizzard employees walked out of work yesterday over the company's decision to ban a pro-Hong-Kong professional He…\n",
            "RT @SpeakeasyJames: Bernier on the repatriation for 2 Canadians held in China.\n",
            "Trudeau claims to defend Canadians (but after 2 years)\n",
            "Schee…\n",
            "RT @HawleyMO: Apple assured me last week that their initial decision to ban this app was a mistake. Looks like the Chinese censors have had…\n",
            "RT @mrbcyber: Blizzard, Apple, and Google remove signs of support for pro-democracy protesters, in concessions to the Peoples Republic of C…\n",
            "RT @NBCNews: The Houston Rockets interrupted a reporter's question and said their players shouldn't be asked about any off-the-court issues…\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXdtQ3eQG4gQ",
        "colab_type": "text"
      },
      "source": [
        "### Part 2 : How to keep or remove retweets ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UttJrnJQAXN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_search = search_words + \" -filter:retweets\"\n",
        "new_search"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i_2bgVBHQEX",
        "colab_type": "text"
      },
      "source": [
        "Same as before, we collect :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5-yEI9kG3Ef",
        "colab_type": "code",
        "outputId": "63135b7f-4aa2-4cdf-bbff-1c1f61a3f749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "#Collect tweets\n",
        "tweets = tweepy.Cursor(api.search,\n",
        "                      q=search_words,\n",
        "                      lang=\"en\",  \n",
        "                       since=date_since).items(nb_tweets)\n",
        "\n",
        "# Iterate and print tweets\n",
        "\n",
        "[tweet.text for tweet in tweets]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"To be honest,\\nthe whole #BoycottBlizzard seems like hindsight.\\nI mean, what's the real reason that meddling with th… https://t.co/m8wszLAH4q\",\n",
              " 'Good 3 Qs: “When was @hkmaplive “used maliciously to target individual officers for violence”?\\nWhen was it used to… https://t.co/VtRybpwAbv',\n",
              " 'RT @JesseKellyDC: REMINDER: There is no “impeachment probe”. The House hasn’t voted on it cause they don’t have the votes and their story i…',\n",
              " 'I think its so cool my great grandfather is from Hong Kong 🇭🇰',\n",
              " 'RT @Nicole__1022: A follow up: CCP netizens reaction to Adam Silvers statement on NBA\\n\\nIf I m not mistaken, thats a blatant statement calli…',\n",
              " \"RT @blakersdozen: Scoop: Blizzard employees walked out of work yesterday over the company's decision to ban a pro-Hong-Kong professional He…\",\n",
              " 'RT @SpeakeasyJames: Bernier on the repatriation for 2 Canadians held in China.\\nTrudeau claims to defend Canadians (but after 2 years)\\nSchee…',\n",
              " 'RT @HawleyMO: Apple assured me last week that their initial decision to ban this app was a mistake. Looks like the Chinese censors have had…',\n",
              " 'RT @mrbcyber: Blizzard, Apple, and Google remove signs of support for pro-democracy protesters, in concessions to the Peoples Republic of C…',\n",
              " \"RT @NBCNews: The Houston Rockets interrupted a reporter's question and said their players shouldn't be asked about any off-the-court issues…\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR7TQkmLJIIk",
        "colab_type": "text"
      },
      "source": [
        "### Part 3 : Who's tweeting about our topic ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvaVHfxqJWHM",
        "colab_type": "code",
        "outputId": "28402cbb-ec83-49dc-90be-4a61fc1460e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# Collect tweets\n",
        "tweets = tweepy.Cursor(api.search, \n",
        "                           q=new_search,\n",
        "                           lang=\"en\",\n",
        "                           since=date_since).items(5)\n",
        "\n",
        "\n",
        "\n",
        "#Storing in a list and printing the collected tweets \n",
        "  #tweet.user.screen_name to get user's name\n",
        "  #tweet.user.location to get user's provided location\n",
        "\n",
        "users_locs = [[tweet.user.screen_name, tweet.user.location] for tweet in tweets]\n",
        "users_locs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['IPDefenseForum',\n",
              "  'Blizzard won’t ban American players after Hong Kong protest, but team plans to forfeit over boycott #IndoAsiaPac… https://t.co/qzdgoUGX2t'],\n",
              " ['Bariter5', '@Blizzard_Ent Stand up for #HongKong. Revolution in our time'],\n",
              " ['GrownDirtStorm',\n",
              "  '#HongKong #Blizzard #BoycottBlizzard I make me em https://t.co/dQHi2iPy8W'],\n",
              " ['nazbolqueen',\n",
              "  'Blizzard with some Lannister tier punishments on gamers for discussing Hong Kong. \\n\\n#HongKongProtest #HongKong… https://t.co/bajO92LutJ'],\n",
              " ['LillyMuse4',\n",
              "  'From @reddit \\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n#blizzard #blizzardentertainment #blizzardgames #hearthstone #overwatch… https://t.co/Vw8JzluSif']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmlrojktKQXy",
        "colab_type": "text"
      },
      "source": [
        "### Part 4 : Create a pandas dataframe from a list of tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISIIV43UKbu_",
        "colab_type": "code",
        "outputId": "b5030d70-379c-4539-e2f6-cb523220621b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "tweet_text = pandas.DataFrame(data=users_locs, \n",
        "                    columns=['user', \"location\"])\n",
        "tweet_text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nigelcameron</td>\n",
              "      <td>Chiefly Brussels, but also London, DC, Chicago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>transgrrl</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hoodlum420</td>\n",
              "      <td>Hollywood, CA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MichaelDavSmith</td>\n",
              "      <td>Chicago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GingeKingYT</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              user                                        location\n",
              "0     nigelcameron  Chiefly Brussels, but also London, DC, Chicago\n",
              "1        transgrrl                                                \n",
              "2       Hoodlum420                                   Hollywood, CA\n",
              "3  MichaelDavSmith                                         Chicago\n",
              "4      GingeKingYT                                                "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjF7tFFPKrED",
        "colab_type": "text"
      },
      "source": [
        "We have empty rows for column 'location cause some users have refused to share their locations with Twitter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sspkLodFLEnq",
        "colab_type": "text"
      },
      "source": [
        "### Part 5 : Customizing twitter queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxu1fvehLPfV",
        "colab_type": "text"
      },
      "source": [
        "Look at [twitter API](https://developer.twitter.com/en/docs/tweets/rules-and-filtering/overview/standard-operators) for more infos.\n",
        "\n",
        "We're going to make a query with \"Hongkong + blizzard\" and collect the tweets related : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxmLqPA_K5De",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic = \"hongkong\"\n",
        "new_search = topic+\"  -filter:retweets\"\n",
        "\n",
        "lang = \"en\"\n",
        "\n",
        "tweets = tweepy.Cursor(api.search,\n",
        "                   q=new_search,\n",
        "                   lang=lang,\n",
        "                   since='2018-04-23').items(2000)\n",
        "\n",
        "#all_tweets = [tweet.text for tweet in tweets]\n",
        "#all_tweets[:5]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwZCfUMQR4S3",
        "colab_type": "text"
      },
      "source": [
        "We get tweet informations and store everything in a dataframe : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KU9rzUYLepA",
        "colab_type": "code",
        "outputId": "6f842bfa-1c85-49ef-ba06-b156a9921afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "\n",
        "users_infos = [[tweet.user.screen_name, tweet.user.location, tweet.text,tweet.lang,tweet.favorite_count,tweet.retweet_count,tweet.created_at] for tweet in tweets]\n",
        "users_infos\n",
        "\n",
        "\n",
        "\n",
        "df_tweets = pandas.DataFrame(data=users_infos, \n",
        "                    columns=['user', \"location\",\"tweet content\",\"language\",\"nb_favorite\",\"nb_retweet\",\"created_at\"])\n",
        "df_tweets\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>location</th>\n",
              "      <th>tweet content</th>\n",
              "      <th>language</th>\n",
              "      <th>nb_favorite</th>\n",
              "      <th>nb_retweet</th>\n",
              "      <th>created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>whereisskeleton</td>\n",
              "      <td></td>\n",
              "      <td>@ftchina Actually this is where the problem th...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-10-25 00:11:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LincolnHKy</td>\n",
              "      <td>Hong Kong</td>\n",
              "      <td>@_jasmineleung_ The sufficient autonomy and go...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-10-25 00:10:50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LincolnHKy</td>\n",
              "      <td>Hong Kong</td>\n",
              "      <td>@BritonsHK The sufficient autonomy and governe...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-10-25 00:10:29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gnokgnohtnads</td>\n",
              "      <td></td>\n",
              "      <td>@tictoc @VP Freedom should be a human right, s...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-10-25 00:10:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HongkongerView</td>\n",
              "      <td></td>\n",
              "      <td>@Reuters Thank you Mr Vice President! #hongkon...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-10-25 00:10:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>HongKongFP</td>\n",
              "      <td>Hong Kong</td>\n",
              "      <td>Ernie Chow and other organisers of the rally i...</td>\n",
              "      <td>en</td>\n",
              "      <td>46</td>\n",
              "      <td>30</td>\n",
              "      <td>2019-10-24 11:36:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>ruby3456789</td>\n",
              "      <td>香港</td>\n",
              "      <td>@euronews @tc53133635 UK please make sure #ccp...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-10-24 11:36:29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>Teddywade32</td>\n",
              "      <td>Rayong, TH</td>\n",
              "      <td>The fools cannot agree on their own southern b...</td>\n",
              "      <td>en</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-10-24 11:35:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>barcelunaR</td>\n",
              "      <td>Barcelona</td>\n",
              "      <td>LIVE: Simultaneous demonstrations are currentl...</td>\n",
              "      <td>en</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>2019-10-24 11:35:22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>ruby3456789</td>\n",
              "      <td>香港</td>\n",
              "      <td>@ABC @tc53133635 UK please make sure #ccp comp...</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-10-24 11:35:21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 user    location  ... nb_retweet          created_at\n",
              "0     whereisskeleton              ...          0 2019-10-25 00:11:38\n",
              "1          LincolnHKy   Hong Kong  ...          0 2019-10-25 00:10:50\n",
              "2          LincolnHKy   Hong Kong  ...          0 2019-10-25 00:10:29\n",
              "3       gnokgnohtnads              ...          0 2019-10-25 00:10:25\n",
              "4      HongkongerView              ...          0 2019-10-25 00:10:14\n",
              "...               ...         ...  ...        ...                 ...\n",
              "1995       HongKongFP   Hong Kong  ...         30 2019-10-24 11:36:47\n",
              "1996      ruby3456789          香港  ...          0 2019-10-24 11:36:29\n",
              "1997      Teddywade32  Rayong, TH  ...          0 2019-10-24 11:35:30\n",
              "1998       barcelunaR   Barcelona  ...          4 2019-10-24 11:35:22\n",
              "1999      ruby3456789          香港  ...          0 2019-10-24 11:35:21\n",
              "\n",
              "[2000 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCnngeG_Qawy",
        "colab_type": "text"
      },
      "source": [
        "##Export a csv to drive or on local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmo5-TJ8M7RZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to export from google collab :\n",
        "from google.colab import files\n",
        "\n",
        "#add datetime to filename\n",
        "import time\n",
        "date = time.strftime(\"%d-%m-%Y__%H_%M_%S\")\n",
        "savename = \"df_tweets_raw_\"+topic+\"_\"+lang+\"_\"+date+\".csv\"\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zog8IzuYRM5Z",
        "colab_type": "text"
      },
      "source": [
        "### sur le drive "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvqa6QNsRUoD",
        "colab_type": "text"
      },
      "source": [
        "Follow these steps to do save on the drive :\n",
        "\n",
        "\n",
        "1. We need to setup our drive first, run this :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75vOR1vrRTzV",
        "colab_type": "code",
        "outputId": "b1bd0e38-fa63-4431-d54e-9f42fdb5d42e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#need to do this only once\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xTELXHp3S_3U"
      },
      "source": [
        "\n",
        "2.   Click on the URL, choose which account you're workin on, and copy paste the link in the box. You should get something like this :\n",
        "![](https://miro.medium.com/max/2234/1*ZpgiKaB2RSo_nTAvo9QNbg.png)\n",
        "\n",
        "\n",
        "3. [optionnal] You could naviguate to your folder and see what you have in your drive, here we want to go there. Useful when you want to define path variable :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWXSQ0RERNjD",
        "colab_type": "code",
        "outputId": "1ff28d5b-b609-440a-9356-357b7bfc4943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls /content/gdrive/Shared\\ drives/PFE_ING3_ESTIA/data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cleaned_data  raw_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sxnHaxxTcS6",
        "colab_type": "text"
      },
      "source": [
        "4. Setup done! We need to save our model in GDrive :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnJT8jrgYa-j",
        "colab_type": "code",
        "outputId": "b86a195c-d718-4217-cede-d56e4be29e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "  print(\"savename : \",savename,\"\\n\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "savename :  df_tweets_raw_hongkong_en_25-10-2019__00_12_44.csv \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HUiFXu4TlEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tweets.to_csv(savename)\n",
        "\n",
        "# copy paste savename and path printed below\n",
        "#!cp savename path\n",
        "\n",
        "#work but nor adaptative (ex : CRON ...) \n",
        "!cp df_tweets_raw_hongkong_en_25-10-2019__00_12_44.csv  /content/gdrive/Shared\\ drives/PFE_ING3_ESTIA/data/raw_data\n",
        "\n",
        "#good for cron extract but need to work on shared drives\n",
        "# import shutil\n",
        "# path = \"/content/gdrive/My Drive/\"\n",
        "# shutil.copy(savename, path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBa6eTNBhHp_",
        "colab_type": "code",
        "outputId": "7f74f397-fea4-437a-9f24-3ef40001db9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls /content/gdrive/Shared\\ drives/PFE_ING3_ESTIA/data/raw_data"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_tweets_raw_hongkong_en_25-10-2019__00_12_44.csv  hongkong  rouen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zEMMW8bhHkl",
        "colab_type": "code",
        "outputId": "d600df6e-1367-42cc-9553-7c6a25ead1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMhsPFfvQ5Nr",
        "colab_type": "text"
      },
      "source": [
        "### en local\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuhwucd8S75Y",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_16QROCTTKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tweets.to_csv(savename)\n",
        "files.download(savename)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}